{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Networks\n",
    "\n",
    "We now use Tensorflow to classify nodes in a graph using Graph Convolution Networks.\n",
    "\n",
    "First, install gcn on your machine using the 'python setup.py install' command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise for semisupervised classification on citation networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from gcn.utils import *\n",
    "from gcn.models import Model,MLP\n",
    "from gcn.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('dataset', 'cora', 'Dataset string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_string('dataset_2', 'citeseer', 'Dataset_2 string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_string('model', 'gcn', 'Model string.')  # 'gcn', 'gcn_cheby', 'dense'\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "#flags.DEFINE_float('learning_rate', 0.1, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "#flags.DEFINE_float('dropout', 0., 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "#flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 100, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(preds, labels, mask):\n",
    "    \"\"\"Softmax cross-entropy loss with masking.\"\"\"\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_mean_square_error(preds,labels,mask):\n",
    "    \"\"\" L-2 loss \"\"\"\n",
    "    loss = tf.nn.l2_loss(preds - labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_accuracy(preds, labels, mask):\n",
    "    \"\"\"Accuracy with masking.\"\"\"\n",
    "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(correct_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GCN(Model):\n",
    "    def __init__(self, placeholders, input_dim, **kwargs):\n",
    "        super(GCN, self).__init__(**kwargs)\n",
    "\n",
    "        self.inputs = placeholders['features']\n",
    "        self.input_dim = input_dim\n",
    "        # self.input_dim = self.inputs.get_shape().as_list()[1]  # To be supported in future Tensorflow versions\n",
    "        self.output_dim = placeholders['labels'].get_shape().as_list()[1]\n",
    "        self.placeholders = placeholders\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n",
    "\n",
    "        self.build()\n",
    "\n",
    "    def _loss(self):\n",
    "        # Weight decay loss\n",
    "        for var in self.layers[0].vars.values():\n",
    "            self.loss += FLAGS.weight_decay * tf.nn.l2_loss(var)\n",
    "\n",
    "        # Cross entropy error\n",
    "        self.loss += masked_mean_square_error(self.outputs, self.placeholders['labels'],\n",
    "                                              self.placeholders['labels_mask'])\n",
    "        # self.loss += masked_softmax_cross_entropy(self.outputs, self.placeholders['labels'],\n",
    "        #                                           self.placeholders['labels_mask'])\n",
    "\n",
    "    def _accuracy(self):\n",
    "        self.accuracy = masked_accuracy(self.outputs, self.placeholders['labels'],\n",
    "                                        self.placeholders['labels_mask'])\n",
    "\n",
    "    def _build(self):\n",
    "\n",
    "        self.layers.append(GraphConvolution(input_dim=self.input_dim,\n",
    "                                            output_dim=FLAGS.hidden1,\n",
    "                                            placeholders=self.placeholders,\n",
    "                                            act=tf.nn.relu,\n",
    "                                            dropout=True,\n",
    "                                            sparse_inputs=True,\n",
    "                                            logging=self.logging))\n",
    "\n",
    "        self.layers.append(GraphConvolution(input_dim=FLAGS.hidden1,\n",
    "                                            output_dim=self.output_dim,\n",
    "                                            placeholders=self.placeholders,\n",
    "                                            act=lambda x: x,\n",
    "                                            dropout=True,\n",
    "                                            logging=self.logging))\n",
    "\n",
    "    def predict(self):\n",
    "        return tf.nn.softmax(self.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_adj(adj):\n",
    "    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    return sparse_to_tuple(adj_normalized)\n",
    "#    adj_square = np.power(adj,2).tocoo()\n",
    "#    return sparse_to_tuple(adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(FLAGS.dataset)\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "if FLAGS.model == 'gcn':\n",
    "    support = [preprocess_adj(adj)]\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'dense':\n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = MLP\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n",
    "\n",
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 70.30534 train_acc= 0.07143 val_loss= 248.96060 val_acc= 0.18400 time= 0.04883\n",
      "Epoch: 0002 train_loss= 69.51312 train_acc= 0.28571 val_loss= 247.73361 val_acc= 0.29600 time= 0.01511\n",
      "Epoch: 0003 train_loss= 69.11311 train_acc= 0.45714 val_loss= 246.32149 val_acc= 0.40200 time= 0.01950\n",
      "Epoch: 0004 train_loss= 68.73877 train_acc= 0.57857 val_loss= 244.89812 val_acc= 0.47600 time= 0.01779\n",
      "Epoch: 0005 train_loss= 67.98429 train_acc= 0.69286 val_loss= 243.58395 val_acc= 0.52400 time= 0.02154\n",
      "Epoch: 0006 train_loss= 67.54814 train_acc= 0.73571 val_loss= 242.55818 val_acc= 0.55200 time= 0.02131\n",
      "Epoch: 0007 train_loss= 67.09998 train_acc= 0.80714 val_loss= 241.80969 val_acc= 0.59600 time= 0.01913\n",
      "Epoch: 0008 train_loss= 66.38895 train_acc= 0.79286 val_loss= 241.22533 val_acc= 0.63000 time= 0.01874\n",
      "Epoch: 0009 train_loss= 65.86577 train_acc= 0.87143 val_loss= 240.75558 val_acc= 0.68000 time= 0.01603\n",
      "Epoch: 0010 train_loss= 65.51508 train_acc= 0.86429 val_loss= 240.41539 val_acc= 0.69400 time= 0.01290\n",
      "Epoch: 0011 train_loss= 65.18842 train_acc= 0.90714 val_loss= 240.24200 val_acc= 0.71800 time= 0.01247\n",
      "Epoch: 0012 train_loss= 65.18712 train_acc= 0.94286 val_loss= 240.26888 val_acc= 0.72200 time= 0.01364\n",
      "Epoch: 0013 train_loss= 64.57732 train_acc= 0.89286 val_loss= 240.45993 val_acc= 0.71200 time= 0.01572\n",
      "Epoch: 0014 train_loss= 64.08794 train_acc= 0.90714 val_loss= 240.76788 val_acc= 0.70800 time= 0.01728\n",
      "Epoch: 0015 train_loss= 63.74492 train_acc= 0.90714 val_loss= 241.08102 val_acc= 0.69600 time= 0.01528\n",
      "Epoch: 0016 train_loss= 63.34270 train_acc= 0.87857 val_loss= 241.38747 val_acc= 0.68600 time= 0.01716\n",
      "Epoch: 0017 train_loss= 62.80936 train_acc= 0.92857 val_loss= 241.60368 val_acc= 0.67400 time= 0.01291\n",
      "Epoch: 0018 train_loss= 62.27464 train_acc= 0.92857 val_loss= 241.74983 val_acc= 0.66800 time= 0.01289\n",
      "Epoch: 0019 train_loss= 62.46304 train_acc= 0.93571 val_loss= 241.84502 val_acc= 0.66200 time= 0.01390\n",
      "Epoch: 0020 train_loss= 61.90032 train_acc= 0.93571 val_loss= 241.91325 val_acc= 0.65800 time= 0.01354\n",
      "Epoch: 0021 train_loss= 61.61905 train_acc= 0.94286 val_loss= 241.94458 val_acc= 0.66200 time= 0.01319\n",
      "Epoch: 0022 train_loss= 61.31013 train_acc= 0.95000 val_loss= 241.99658 val_acc= 0.67000 time= 0.01317\n",
      "Epoch: 0023 train_loss= 61.38594 train_acc= 0.92857 val_loss= 242.08089 val_acc= 0.66400 time= 0.01361\n",
      "Epoch: 0024 train_loss= 61.18523 train_acc= 0.96429 val_loss= 242.16982 val_acc= 0.66000 time= 0.01294\n",
      "Epoch: 0025 train_loss= 60.85730 train_acc= 0.92857 val_loss= 242.30164 val_acc= 0.66000 time= 0.01250\n",
      "Epoch: 0026 train_loss= 60.31426 train_acc= 0.95000 val_loss= 242.44356 val_acc= 0.65800 time= 0.01562\n",
      "Epoch: 0027 train_loss= 59.97717 train_acc= 0.97143 val_loss= 242.60793 val_acc= 0.65600 time= 0.01849\n",
      "Epoch: 0028 train_loss= 60.47728 train_acc= 0.95000 val_loss= 242.78233 val_acc= 0.65200 time= 0.01662\n",
      "Epoch: 0029 train_loss= 59.88424 train_acc= 0.94286 val_loss= 243.00433 val_acc= 0.64400 time= 0.01492\n",
      "Epoch: 0030 train_loss= 59.20360 train_acc= 0.95000 val_loss= 243.28224 val_acc= 0.63800 time= 0.01772\n",
      "Epoch: 0031 train_loss= 58.93139 train_acc= 0.95714 val_loss= 243.58452 val_acc= 0.62800 time= 0.02270\n",
      "Epoch: 0032 train_loss= 59.11779 train_acc= 0.94286 val_loss= 243.89226 val_acc= 0.62400 time= 0.02265\n",
      "Epoch: 0033 train_loss= 59.13826 train_acc= 0.96429 val_loss= 244.14996 val_acc= 0.61400 time= 0.02455\n",
      "Epoch: 0034 train_loss= 59.05579 train_acc= 0.96429 val_loss= 244.37778 val_acc= 0.60600 time= 0.01933\n",
      "Epoch: 0035 train_loss= 58.61590 train_acc= 0.96429 val_loss= 244.58128 val_acc= 0.60000 time= 0.01556\n",
      "Epoch: 0036 train_loss= 58.16898 train_acc= 0.94286 val_loss= 244.74718 val_acc= 0.59400 time= 0.01997\n",
      "Epoch: 0037 train_loss= 57.93875 train_acc= 0.97857 val_loss= 244.89120 val_acc= 0.58600 time= 0.02193\n",
      "Epoch: 0038 train_loss= 58.34875 train_acc= 0.96429 val_loss= 245.04211 val_acc= 0.58200 time= 0.01431\n",
      "Epoch: 0039 train_loss= 58.53677 train_acc= 0.94286 val_loss= 245.12827 val_acc= 0.57000 time= 0.01374\n",
      "Epoch: 0040 train_loss= 57.53323 train_acc= 0.96429 val_loss= 245.20226 val_acc= 0.57400 time= 0.01368\n",
      "Epoch: 0041 train_loss= 57.75428 train_acc= 0.95714 val_loss= 245.29036 val_acc= 0.57200 time= 0.01349\n",
      "Epoch: 0042 train_loss= 57.53281 train_acc= 0.95714 val_loss= 245.35649 val_acc= 0.57000 time= 0.01273\n",
      "Epoch: 0043 train_loss= 57.49787 train_acc= 0.97857 val_loss= 245.41107 val_acc= 0.58000 time= 0.01235\n",
      "Epoch: 0044 train_loss= 57.47269 train_acc= 0.95714 val_loss= 245.43762 val_acc= 0.58000 time= 0.01215\n",
      "Epoch: 0045 train_loss= 57.06778 train_acc= 0.95000 val_loss= 245.47250 val_acc= 0.58200 time= 0.01233\n",
      "Epoch: 0046 train_loss= 56.62552 train_acc= 0.97857 val_loss= 245.54617 val_acc= 0.57800 time= 0.01261\n",
      "Epoch: 0047 train_loss= 57.10340 train_acc= 0.95000 val_loss= 245.67821 val_acc= 0.56800 time= 0.01299\n",
      "Epoch: 0048 train_loss= 56.56792 train_acc= 0.97857 val_loss= 245.79262 val_acc= 0.56000 time= 0.01268\n",
      "Epoch: 0049 train_loss= 56.82578 train_acc= 0.96429 val_loss= 245.95070 val_acc= 0.55400 time= 0.01598\n",
      "Epoch: 0050 train_loss= 56.64241 train_acc= 0.97143 val_loss= 246.09363 val_acc= 0.54600 time= 0.01744\n",
      "Epoch: 0051 train_loss= 56.70467 train_acc= 0.96429 val_loss= 246.22008 val_acc= 0.54600 time= 0.01661\n",
      "Epoch: 0052 train_loss= 56.96268 train_acc= 0.94286 val_loss= 246.30521 val_acc= 0.54000 time= 0.01259\n",
      "Epoch: 0053 train_loss= 56.00894 train_acc= 0.97857 val_loss= 246.37564 val_acc= 0.52800 time= 0.01307\n",
      "Epoch: 0054 train_loss= 55.87854 train_acc= 0.95714 val_loss= 246.42825 val_acc= 0.52800 time= 0.01387\n",
      "Epoch: 0055 train_loss= 56.36410 train_acc= 0.99286 val_loss= 246.41222 val_acc= 0.52600 time= 0.01338\n",
      "Epoch: 0056 train_loss= 55.54876 train_acc= 0.95714 val_loss= 246.42532 val_acc= 0.52600 time= 0.01431\n",
      "Epoch: 0057 train_loss= 56.41449 train_acc= 0.97143 val_loss= 246.47092 val_acc= 0.52000 time= 0.01950\n",
      "Epoch: 0058 train_loss= 55.70937 train_acc= 0.95714 val_loss= 246.58694 val_acc= 0.51800 time= 0.01261\n",
      "Epoch: 0059 train_loss= 55.64563 train_acc= 0.97857 val_loss= 246.67366 val_acc= 0.52200 time= 0.01436\n",
      "Epoch: 0060 train_loss= 56.37223 train_acc= 0.97143 val_loss= 246.77589 val_acc= 0.52000 time= 0.01273\n",
      "Epoch: 0061 train_loss= 56.01413 train_acc= 0.96429 val_loss= 246.88878 val_acc= 0.51000 time= 0.01258\n",
      "Epoch: 0062 train_loss= 55.74741 train_acc= 0.97857 val_loss= 247.01826 val_acc= 0.50600 time= 0.01502\n",
      "Epoch: 0063 train_loss= 55.76550 train_acc= 0.98571 val_loss= 247.10777 val_acc= 0.50400 time= 0.01998\n",
      "Epoch: 0064 train_loss= 55.75224 train_acc= 0.95714 val_loss= 247.17154 val_acc= 0.51200 time= 0.01414\n",
      "Epoch: 0065 train_loss= 55.37880 train_acc= 0.97857 val_loss= 247.22740 val_acc= 0.51000 time= 0.01406\n",
      "Epoch: 0066 train_loss= 55.03484 train_acc= 0.98571 val_loss= 247.20908 val_acc= 0.51600 time= 0.01285\n",
      "Epoch: 0067 train_loss= 54.95682 train_acc= 0.96429 val_loss= 247.18752 val_acc= 0.51200 time= 0.01380\n",
      "Epoch: 0068 train_loss= 54.64714 train_acc= 0.99286 val_loss= 247.15485 val_acc= 0.51200 time= 0.01578\n",
      "Epoch: 0069 train_loss= 55.10022 train_acc= 0.97143 val_loss= 247.12294 val_acc= 0.50600 time= 0.01367\n",
      "Epoch: 0070 train_loss= 54.28703 train_acc= 0.97857 val_loss= 247.10889 val_acc= 0.49600 time= 0.01792\n",
      "Epoch: 0071 train_loss= 55.46737 train_acc= 0.95000 val_loss= 247.11449 val_acc= 0.49800 time= 0.01790\n",
      "Epoch: 0072 train_loss= 54.87784 train_acc= 0.95714 val_loss= 247.18515 val_acc= 0.48600 time= 0.01640\n",
      "Epoch: 0073 train_loss= 54.80952 train_acc= 0.99286 val_loss= 247.31596 val_acc= 0.48000 time= 0.02031\n",
      "Epoch: 0074 train_loss= 55.26064 train_acc= 0.97143 val_loss= 247.44698 val_acc= 0.47800 time= 0.01804\n",
      "Epoch: 0075 train_loss= 54.34774 train_acc= 0.97857 val_loss= 247.59702 val_acc= 0.47200 time= 0.02456\n",
      "Epoch: 0076 train_loss= 54.21735 train_acc= 0.96429 val_loss= 247.67725 val_acc= 0.47000 time= 0.01943\n",
      "Epoch: 0077 train_loss= 53.51711 train_acc= 0.99286 val_loss= 247.66876 val_acc= 0.46200 time= 0.02079\n",
      "Epoch: 0078 train_loss= 54.44504 train_acc= 0.96429 val_loss= 247.65144 val_acc= 0.46600 time= 0.01831\n",
      "Epoch: 0079 train_loss= 54.39682 train_acc= 0.95714 val_loss= 247.65509 val_acc= 0.47200 time= 0.01626\n",
      "Epoch: 0080 train_loss= 54.83321 train_acc= 0.97857 val_loss= 247.60390 val_acc= 0.47200 time= 0.01443\n",
      "Epoch: 0081 train_loss= 54.93000 train_acc= 0.97143 val_loss= 247.53296 val_acc= 0.47200 time= 0.01287\n",
      "Epoch: 0082 train_loss= 53.91839 train_acc= 0.98571 val_loss= 247.49794 val_acc= 0.46800 time= 0.01307\n",
      "Epoch: 0083 train_loss= 54.21942 train_acc= 0.97143 val_loss= 247.48892 val_acc= 0.46400 time= 0.01288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0084 train_loss= 54.26834 train_acc= 0.97857 val_loss= 247.55428 val_acc= 0.46200 time= 0.01421\n",
      "Epoch: 0085 train_loss= 53.28731 train_acc= 0.97143 val_loss= 247.62164 val_acc= 0.46000 time= 0.01544\n",
      "Epoch: 0086 train_loss= 53.82362 train_acc= 0.97143 val_loss= 247.66472 val_acc= 0.46000 time= 0.01731\n",
      "Epoch: 0087 train_loss= 54.12738 train_acc= 0.96429 val_loss= 247.69556 val_acc= 0.46000 time= 0.01674\n",
      "Epoch: 0088 train_loss= 54.02099 train_acc= 0.97143 val_loss= 247.73383 val_acc= 0.45600 time= 0.01282\n",
      "Epoch: 0089 train_loss= 54.42538 train_acc= 0.97143 val_loss= 247.80040 val_acc= 0.45800 time= 0.01318\n",
      "Epoch: 0090 train_loss= 54.70245 train_acc= 0.96429 val_loss= 247.91379 val_acc= 0.46000 time= 0.01427\n",
      "Epoch: 0091 train_loss= 54.62503 train_acc= 0.96429 val_loss= 248.02254 val_acc= 0.46000 time= 0.01331\n",
      "Epoch: 0092 train_loss= 54.10172 train_acc= 0.97143 val_loss= 248.16452 val_acc= 0.46000 time= 0.01268\n",
      "Epoch: 0093 train_loss= 52.92982 train_acc= 0.97857 val_loss= 248.31393 val_acc= 0.46000 time= 0.01300\n",
      "Epoch: 0094 train_loss= 53.02406 train_acc= 0.97143 val_loss= 248.43668 val_acc= 0.45200 time= 0.01391\n",
      "Epoch: 0095 train_loss= 54.17970 train_acc= 0.95714 val_loss= 248.51350 val_acc= 0.45200 time= 0.01228\n",
      "Epoch: 0096 train_loss= 54.98588 train_acc= 0.95000 val_loss= 248.57597 val_acc= 0.43000 time= 0.01248\n",
      "Epoch: 0097 train_loss= 53.56714 train_acc= 0.98571 val_loss= 248.64822 val_acc= 0.42800 time= 0.01231\n",
      "Epoch: 0098 train_loss= 54.08790 train_acc= 0.98571 val_loss= 248.74014 val_acc= 0.42600 time= 0.01451\n",
      "Epoch: 0099 train_loss= 53.89722 train_acc= 0.97143 val_loss= 248.80772 val_acc= 0.41800 time= 0.01525\n",
      "Epoch: 0100 train_loss= 54.38625 train_acc= 0.96429 val_loss= 248.89099 val_acc= 0.41800 time= 0.01797\n",
      "Epoch: 0101 train_loss= 52.94248 train_acc= 0.96429 val_loss= 248.98772 val_acc= 0.42200 time= 0.01447\n",
      "Epoch: 0102 train_loss= 54.36436 train_acc= 0.94286 val_loss= 249.04263 val_acc= 0.41800 time= 0.01310\n",
      "Early stopping...\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Initialize weights\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "train_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "\n",
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "    \n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, y_val, val_mask, placeholders)\n",
    "    validation_loss.append(cost)\n",
    "    validation_accuracy.append(acc)\n",
    "    train_loss.append(outs[1])\n",
    "    train_accuracy.append(outs[2])\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and validation_loss[-1] > np.mean(validation_loss[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: cost= 480.59225 accuracy= 0.47400 time= 0.00769\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_cost, test_acc, test_duration = evaluate(features, support, y_test, test_mask, placeholders)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1199c0828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(train_accuracy,label = 'train_accuracy')\n",
    "plt.plot(train_loss,label = 'train_loss')\n",
    "plt.plot(validation_accuracy, label='validation_accuracy')\n",
    "plt.plot(validation_loss,label='validaton_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. With no weight dacy / dropout  (covered in class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of training accuracy, training loss, validation accuracy and validation loss against the number of steps **without weight decay and without dropout**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Change it to $A^2$ (covered in class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of training accuracy, training loss, validation accuracy and validation loss against the number of steps **after changing the adjacency matrix to $A^2$ **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Change to the $L_2$ loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of training accuracy, training loss, validation accuracy and validation loss against the number of steps **with the loss function being $L_2$ loss**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 70.17213 train_acc= 0.07857 val_loss= 247.88293 val_acc= 0.19400 time= 0.01548\n",
      "Epoch: 0002 train_loss= 69.43874 train_acc= 0.22857 val_loss= 246.43976 val_acc= 0.27800 time= 0.01354\n",
      "Epoch: 0003 train_loss= 68.87204 train_acc= 0.42143 val_loss= 245.13405 val_acc= 0.42800 time= 0.01274\n",
      "Epoch: 0004 train_loss= 68.31245 train_acc= 0.56429 val_loss= 243.97650 val_acc= 0.53800 time= 0.01278\n",
      "Epoch: 0005 train_loss= 67.78450 train_acc= 0.63571 val_loss= 242.99306 val_acc= 0.61000 time= 0.01281\n",
      "Epoch: 0006 train_loss= 67.33092 train_acc= 0.70000 val_loss= 242.26442 val_acc= 0.62400 time= 0.01414\n",
      "Epoch: 0007 train_loss= 66.69719 train_acc= 0.80714 val_loss= 241.85512 val_acc= 0.63200 time= 0.01449\n",
      "Epoch: 0008 train_loss= 66.63135 train_acc= 0.81429 val_loss= 241.62746 val_acc= 0.63000 time= 0.01391\n",
      "Epoch: 0009 train_loss= 66.28365 train_acc= 0.77857 val_loss= 241.45602 val_acc= 0.63600 time= 0.01290\n",
      "Epoch: 0010 train_loss= 65.58755 train_acc= 0.82143 val_loss= 241.26761 val_acc= 0.64400 time= 0.01320\n",
      "Epoch: 0011 train_loss= 65.49610 train_acc= 0.87857 val_loss= 241.09497 val_acc= 0.65600 time= 0.01241\n",
      "Epoch: 0012 train_loss= 65.26701 train_acc= 0.85714 val_loss= 241.00870 val_acc= 0.65800 time= 0.01422\n",
      "Epoch: 0013 train_loss= 64.96433 train_acc= 0.88571 val_loss= 240.98927 val_acc= 0.66600 time= 0.01363\n",
      "Epoch: 0014 train_loss= 64.59863 train_acc= 0.93571 val_loss= 240.96651 val_acc= 0.66800 time= 0.01267\n",
      "Epoch: 0015 train_loss= 64.38953 train_acc= 0.87143 val_loss= 241.01428 val_acc= 0.67600 time= 0.01451\n",
      "Epoch: 0016 train_loss= 63.27377 train_acc= 0.90714 val_loss= 241.02864 val_acc= 0.67000 time= 0.01504\n",
      "Epoch: 0017 train_loss= 63.44402 train_acc= 0.94286 val_loss= 241.04686 val_acc= 0.67800 time= 0.01851\n",
      "Epoch: 0018 train_loss= 62.89306 train_acc= 0.96429 val_loss= 241.03188 val_acc= 0.68200 time= 0.01658\n",
      "Epoch: 0019 train_loss= 62.98011 train_acc= 0.94286 val_loss= 241.05370 val_acc= 0.68400 time= 0.01257\n",
      "Epoch: 0020 train_loss= 62.17611 train_acc= 0.91429 val_loss= 241.07043 val_acc= 0.67200 time= 0.01257\n",
      "Epoch: 0021 train_loss= 62.05483 train_acc= 0.95000 val_loss= 241.13063 val_acc= 0.66600 time= 0.01355\n",
      "Epoch: 0022 train_loss= 61.84432 train_acc= 0.94286 val_loss= 241.24071 val_acc= 0.66400 time= 0.01271\n",
      "Epoch: 0023 train_loss= 61.62558 train_acc= 0.97143 val_loss= 241.36104 val_acc= 0.66800 time= 0.01262\n",
      "Epoch: 0024 train_loss= 61.62121 train_acc= 0.92857 val_loss= 241.47551 val_acc= 0.66400 time= 0.01260\n",
      "Epoch: 0025 train_loss= 61.02090 train_acc= 0.95000 val_loss= 241.61833 val_acc= 0.66000 time= 0.01278\n",
      "Epoch: 0026 train_loss= 60.87886 train_acc= 0.94286 val_loss= 241.84119 val_acc= 0.65600 time= 0.01286\n",
      "Epoch: 0027 train_loss= 60.83726 train_acc= 0.97143 val_loss= 242.08049 val_acc= 0.65200 time= 0.01422\n",
      "Epoch: 0028 train_loss= 60.28828 train_acc= 0.97857 val_loss= 242.31438 val_acc= 0.64400 time= 0.01291\n",
      "Epoch: 0029 train_loss= 60.34363 train_acc= 0.95714 val_loss= 242.51634 val_acc= 0.64600 time= 0.01465\n",
      "Epoch: 0030 train_loss= 60.11247 train_acc= 0.96429 val_loss= 242.65210 val_acc= 0.63400 time= 0.01739\n",
      "Epoch: 0031 train_loss= 59.50899 train_acc= 0.96429 val_loss= 242.76445 val_acc= 0.63400 time= 0.01578\n",
      "Epoch: 0032 train_loss= 59.48114 train_acc= 0.97143 val_loss= 242.85008 val_acc= 0.63000 time= 0.01394\n",
      "Epoch: 0033 train_loss= 59.94939 train_acc= 0.95000 val_loss= 242.92482 val_acc= 0.62400 time= 0.01306\n",
      "Epoch: 0034 train_loss= 59.17621 train_acc= 0.96429 val_loss= 242.98749 val_acc= 0.62600 time= 0.01244\n",
      "Epoch: 0035 train_loss= 58.57167 train_acc= 0.97143 val_loss= 243.03836 val_acc= 0.62400 time= 0.01451\n",
      "Epoch: 0036 train_loss= 57.97660 train_acc= 0.97143 val_loss= 243.15273 val_acc= 0.61000 time= 0.01298\n",
      "Epoch: 0037 train_loss= 58.43418 train_acc= 0.95714 val_loss= 243.31248 val_acc= 0.60200 time= 0.01265\n",
      "Epoch: 0038 train_loss= 58.70406 train_acc= 0.97143 val_loss= 243.51222 val_acc= 0.59800 time= 0.01270\n",
      "Epoch: 0039 train_loss= 57.92134 train_acc= 0.98571 val_loss= 243.75664 val_acc= 0.59800 time= 0.04268\n",
      "Epoch: 0040 train_loss= 58.64090 train_acc= 0.93571 val_loss= 244.04034 val_acc= 0.59000 time= 0.01565\n",
      "Epoch: 0041 train_loss= 57.46902 train_acc= 0.97143 val_loss= 244.30869 val_acc= 0.58600 time= 0.01544\n",
      "Epoch: 0042 train_loss= 56.92758 train_acc= 0.97857 val_loss= 244.54048 val_acc= 0.58200 time= 0.02476\n",
      "Epoch: 0043 train_loss= 57.37325 train_acc= 0.97143 val_loss= 244.75961 val_acc= 0.58600 time= 0.02062\n",
      "Epoch: 0044 train_loss= 58.10430 train_acc= 0.97857 val_loss= 244.96335 val_acc= 0.58800 time= 0.01346\n",
      "Epoch: 0045 train_loss= 57.14798 train_acc= 0.98571 val_loss= 245.14822 val_acc= 0.58400 time= 0.01283\n",
      "Epoch: 0046 train_loss= 57.37749 train_acc= 0.95714 val_loss= 245.31644 val_acc= 0.58400 time= 0.01454\n",
      "Epoch: 0047 train_loss= 56.19595 train_acc= 1.00000 val_loss= 245.43094 val_acc= 0.57600 time= 0.01293\n",
      "Epoch: 0048 train_loss= 56.67159 train_acc= 0.97143 val_loss= 245.50830 val_acc= 0.57200 time= 0.01267\n",
      "Epoch: 0049 train_loss= 57.23817 train_acc= 0.97857 val_loss= 245.54219 val_acc= 0.57200 time= 0.01296\n",
      "Epoch: 0050 train_loss= 56.94776 train_acc= 0.97143 val_loss= 245.59143 val_acc= 0.57800 time= 0.01216\n",
      "Epoch: 0051 train_loss= 56.35590 train_acc= 0.96429 val_loss= 245.65019 val_acc= 0.56800 time= 0.01286\n",
      "Epoch: 0052 train_loss= 56.49995 train_acc= 0.99286 val_loss= 245.71982 val_acc= 0.57200 time= 0.01236\n",
      "Epoch: 0053 train_loss= 56.85714 train_acc= 0.98571 val_loss= 245.86496 val_acc= 0.55800 time= 0.01272\n",
      "Epoch: 0054 train_loss= 56.91386 train_acc= 0.98571 val_loss= 245.99747 val_acc= 0.56000 time= 0.01283\n",
      "Epoch: 0055 train_loss= 56.52957 train_acc= 0.99286 val_loss= 246.13150 val_acc= 0.55400 time= 0.01450\n",
      "Epoch: 0056 train_loss= 55.88757 train_acc= 0.99286 val_loss= 246.23320 val_acc= 0.55200 time= 0.01777\n",
      "Epoch: 0057 train_loss= 56.13735 train_acc= 0.98571 val_loss= 246.34686 val_acc= 0.54800 time= 0.01455\n",
      "Epoch: 0058 train_loss= 56.38074 train_acc= 0.95714 val_loss= 246.44264 val_acc= 0.54400 time= 0.01845\n",
      "Epoch: 0059 train_loss= 56.10804 train_acc= 0.97143 val_loss= 246.53639 val_acc= 0.53600 time= 0.02533\n",
      "Epoch: 0060 train_loss= 55.66180 train_acc= 0.96429 val_loss= 246.61923 val_acc= 0.53400 time= 0.02835\n",
      "Epoch: 0061 train_loss= 55.61399 train_acc= 0.97857 val_loss= 246.68141 val_acc= 0.53000 time= 0.01857\n",
      "Epoch: 0062 train_loss= 54.51307 train_acc= 0.98571 val_loss= 246.72133 val_acc= 0.51800 time= 0.01805\n",
      "Epoch: 0063 train_loss= 55.21593 train_acc= 0.97143 val_loss= 246.71893 val_acc= 0.51200 time= 0.02383\n",
      "Epoch: 0064 train_loss= 55.36450 train_acc= 0.94286 val_loss= 246.74988 val_acc= 0.50600 time= 0.01759\n",
      "Epoch: 0065 train_loss= 55.45452 train_acc= 0.97143 val_loss= 246.77132 val_acc= 0.50200 time= 0.02186\n",
      "Epoch: 0066 train_loss= 54.89481 train_acc= 0.97143 val_loss= 246.82120 val_acc= 0.50200 time= 0.08416\n",
      "Epoch: 0067 train_loss= 54.99895 train_acc= 0.95714 val_loss= 246.87027 val_acc= 0.50200 time= 0.01325\n",
      "Epoch: 0068 train_loss= 54.19506 train_acc= 0.96429 val_loss= 246.95396 val_acc= 0.50000 time= 0.01396\n",
      "Epoch: 0069 train_loss= 54.87012 train_acc= 0.99286 val_loss= 247.04855 val_acc= 0.49400 time= 0.01411\n",
      "Epoch: 0070 train_loss= 54.56659 train_acc= 0.97143 val_loss= 247.16914 val_acc= 0.48400 time= 0.01316\n",
      "Epoch: 0071 train_loss= 53.87317 train_acc= 0.98571 val_loss= 247.29747 val_acc= 0.48000 time= 0.01316\n",
      "Epoch: 0072 train_loss= 54.39629 train_acc= 0.96429 val_loss= 247.40341 val_acc= 0.47400 time= 0.01282\n",
      "Epoch: 0073 train_loss= 54.94928 train_acc= 0.97857 val_loss= 247.44949 val_acc= 0.46400 time= 0.01427\n",
      "Epoch: 0074 train_loss= 54.60042 train_acc= 0.97143 val_loss= 247.47731 val_acc= 0.46000 time= 0.01618\n",
      "Epoch: 0075 train_loss= 54.18063 train_acc= 0.96429 val_loss= 247.49615 val_acc= 0.46000 time= 0.01664\n",
      "Epoch: 0076 train_loss= 55.39570 train_acc= 0.98571 val_loss= 247.51421 val_acc= 0.47000 time= 0.01694\n",
      "Epoch: 0077 train_loss= 54.19107 train_acc= 0.96429 val_loss= 247.53151 val_acc= 0.47000 time= 0.01319\n",
      "Epoch: 0078 train_loss= 54.03947 train_acc= 0.98571 val_loss= 247.55681 val_acc= 0.46600 time= 0.01450\n",
      "Epoch: 0079 train_loss= 54.53146 train_acc= 0.96429 val_loss= 247.58920 val_acc= 0.46800 time= 0.01360\n",
      "Epoch: 0080 train_loss= 55.08019 train_acc= 0.97857 val_loss= 247.67389 val_acc= 0.47200 time= 0.01382\n",
      "Epoch: 0081 train_loss= 54.39564 train_acc= 0.95000 val_loss= 247.76712 val_acc= 0.46800 time= 0.01298\n",
      "Epoch: 0082 train_loss= 54.86862 train_acc= 0.95000 val_loss= 247.85387 val_acc= 0.46800 time= 0.01230\n",
      "Epoch: 0083 train_loss= 54.01924 train_acc= 0.98571 val_loss= 247.92184 val_acc= 0.47000 time= 0.01267\n",
      "Epoch: 0084 train_loss= 54.94858 train_acc= 0.96429 val_loss= 247.99680 val_acc= 0.47000 time= 0.01239\n",
      "Epoch: 0085 train_loss= 53.70664 train_acc= 0.97857 val_loss= 248.05034 val_acc= 0.46000 time= 0.01288\n",
      "Epoch: 0086 train_loss= 53.68050 train_acc= 0.99286 val_loss= 248.08035 val_acc= 0.45600 time= 0.01270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0087 train_loss= 54.02000 train_acc= 0.98571 val_loss= 248.14159 val_acc= 0.45600 time= 0.01438\n",
      "Epoch: 0088 train_loss= 54.35558 train_acc= 0.97143 val_loss= 248.19489 val_acc= 0.46000 time= 0.01587\n",
      "Epoch: 0089 train_loss= 54.57681 train_acc= 0.97143 val_loss= 248.27771 val_acc= 0.46000 time= 0.01615\n",
      "Epoch: 0090 train_loss= 53.99089 train_acc= 0.97857 val_loss= 248.37361 val_acc= 0.45400 time= 0.01764\n",
      "Epoch: 0091 train_loss= 53.94865 train_acc= 0.97143 val_loss= 248.46854 val_acc= 0.45200 time= 0.01325\n",
      "Epoch: 0092 train_loss= 53.32748 train_acc= 0.99286 val_loss= 248.55003 val_acc= 0.45200 time= 0.01288\n",
      "Epoch: 0093 train_loss= 53.39418 train_acc= 0.99286 val_loss= 248.60071 val_acc= 0.44600 time= 0.01263\n",
      "Epoch: 0094 train_loss= 53.73022 train_acc= 0.96429 val_loss= 248.60922 val_acc= 0.44800 time= 0.01238\n",
      "Epoch: 0095 train_loss= 54.00950 train_acc= 0.97143 val_loss= 248.55411 val_acc= 0.44600 time= 0.01229\n",
      "Epoch: 0096 train_loss= 53.16956 train_acc= 0.97143 val_loss= 248.49576 val_acc= 0.44200 time= 0.01450\n",
      "Epoch: 0097 train_loss= 53.73998 train_acc= 0.97857 val_loss= 248.43596 val_acc= 0.43800 time= 0.01391\n",
      "Epoch: 0098 train_loss= 53.20363 train_acc= 0.97143 val_loss= 248.36458 val_acc= 0.41800 time= 0.01267\n",
      "Epoch: 0099 train_loss= 52.96763 train_acc= 0.98571 val_loss= 248.27087 val_acc= 0.41800 time= 0.01290\n",
      "Epoch: 0100 train_loss= 53.18164 train_acc= 0.97857 val_loss= 248.21432 val_acc= 0.41800 time= 0.01326\n",
      "Epoch: 0101 train_loss= 53.54897 train_acc= 0.96429 val_loss= 248.16530 val_acc= 0.42000 time= 0.01911\n",
      "Epoch: 0102 train_loss= 53.94534 train_acc= 0.96429 val_loss= 248.13586 val_acc= 0.43000 time= 0.03004\n",
      "Early stopping...\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Initialize weights\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "train_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "\n",
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "    \n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, y_val, val_mask, placeholders)\n",
    "    validation_loss.append(cost)\n",
    "    validation_accuracy.append(acc)\n",
    "    train_loss.append(outs[1])\n",
    "    train_accuracy.append(outs[2])\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and validation_loss[-1] > np.mean(validation_loss[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEYCAYAAAAAk8LPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e2334a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p1 = plt.subplot(211)\n",
    "p2 = plt.subplot(212)\n",
    "\n",
    "p1.plot(train_accuracy,label = 'train_accuracy')\n",
    "p1.plot(validation_accuracy, label='validation_accuracy')\n",
    "p1.legend()\n",
    "\n",
    "p2.plot(train_loss,label = 'train_loss')\n",
    "p2.plot(validation_loss,label='validaton_loss')\n",
    "p2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Change the input graph/label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the input graphs using a Stochastic Block Model. The number of nodes should be 500, and then feed the true labels using $20%$ of the nodes. The degree of a node must be used as the feature.\n",
    "Make a plot of training accuracy, training loss, validation accuracy and validation loss against the number of steps for this input graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "def is_sameCluster(N, i, j):\n",
    "    if ((i <= (N+1)/2) and (j <= (N+1)/2)) or ((i > (N+1)/2) and (j > (N+1)/2)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def addEdge(G, prob, i, j):\n",
    "    temp = random.uniform(0, 1)\n",
    "    if temp < prob:\n",
    "        G.add_edge(i, j)        \n",
    "        \n",
    "def generateGraph(N, alpha):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(1, N+1))\n",
    "    nodes = G.nodes()\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            if is_sameCluster(N, i, j):\n",
    "                prob = 0.5 + alpha\n",
    "            else:\n",
    "                prob = 0.5 - alpha\n",
    "            addEdge(G, prob, i, j)\n",
    "            \n",
    "    for (i,j) in G.edges():\n",
    "        G[i][j]['d'] = len(set(G.neighbors(i)).intersection(set(G.neighbors(j))))\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "G = generateGraph(500, 0.3)\n",
    "adjacency = nx.adjacency_matrix(G).todense()\n",
    "print(adjacency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulswamy/Dropbox/ie532/submissions/ex5/gcn/utils.py:97: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(FLAGS.dataset_2)\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "if FLAGS.model == 'gcn':\n",
    "    support = [preprocess_adj(adj)]\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'dense':\n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = MLP\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n",
    "\n",
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 60.03241 train_acc= 0.22500 val_loss= 247.41069 val_acc= 0.41000 time= 0.05145\n",
      "Epoch: 0002 train_loss= 59.44440 train_acc= 0.43333 val_loss= 246.29999 val_acc= 0.54600 time= 0.02681\n",
      "Epoch: 0003 train_loss= 58.90879 train_acc= 0.51667 val_loss= 245.75726 val_acc= 0.60400 time= 0.02575\n",
      "Epoch: 0004 train_loss= 58.44637 train_acc= 0.72500 val_loss= 245.53174 val_acc= 0.62200 time= 0.02592\n",
      "Epoch: 0005 train_loss= 57.84655 train_acc= 0.77500 val_loss= 245.36873 val_acc= 0.63000 time= 0.02544\n",
      "Epoch: 0006 train_loss= 57.36644 train_acc= 0.78333 val_loss= 245.18605 val_acc= 0.62600 time= 0.02600\n",
      "Epoch: 0007 train_loss= 56.67850 train_acc= 0.87500 val_loss= 244.96838 val_acc= 0.60600 time= 0.02512\n",
      "Epoch: 0008 train_loss= 56.24786 train_acc= 0.88333 val_loss= 244.75908 val_acc= 0.59000 time= 0.02640\n",
      "Epoch: 0009 train_loss= 55.70902 train_acc= 0.89167 val_loss= 244.63945 val_acc= 0.59600 time= 0.02669\n",
      "Epoch: 0010 train_loss= 55.02552 train_acc= 0.89167 val_loss= 244.57333 val_acc= 0.61600 time= 0.02473\n",
      "Epoch: 0011 train_loss= 54.29958 train_acc= 0.90000 val_loss= 244.59389 val_acc= 0.62000 time= 0.02631\n",
      "Epoch: 0012 train_loss= 54.29102 train_acc= 0.90833 val_loss= 244.76399 val_acc= 0.61400 time= 0.02849\n",
      "Epoch: 0013 train_loss= 53.85867 train_acc= 0.88333 val_loss= 245.10381 val_acc= 0.60000 time= 0.03029\n",
      "Epoch: 0014 train_loss= 53.61412 train_acc= 0.93333 val_loss= 245.46606 val_acc= 0.58800 time= 0.02611\n",
      "Epoch: 0015 train_loss= 52.80430 train_acc= 0.91667 val_loss= 245.87241 val_acc= 0.57600 time= 0.02541\n",
      "Epoch: 0016 train_loss= 51.51369 train_acc= 0.95833 val_loss= 246.28180 val_acc= 0.55600 time= 0.02633\n",
      "Epoch: 0017 train_loss= 52.21138 train_acc= 0.90833 val_loss= 246.70715 val_acc= 0.55400 time= 0.02585\n",
      "Epoch: 0018 train_loss= 51.35676 train_acc= 0.90833 val_loss= 247.09570 val_acc= 0.54400 time= 0.02554\n",
      "Epoch: 0019 train_loss= 51.45806 train_acc= 0.93333 val_loss= 247.45778 val_acc= 0.50000 time= 0.02526\n",
      "Epoch: 0020 train_loss= 50.63346 train_acc= 0.92500 val_loss= 247.79649 val_acc= 0.49600 time= 0.02552\n",
      "Epoch: 0021 train_loss= 50.22812 train_acc= 0.94167 val_loss= 248.09091 val_acc= 0.49400 time= 0.02564\n",
      "Epoch: 0022 train_loss= 49.60632 train_acc= 0.94167 val_loss= 248.36092 val_acc= 0.48400 time= 0.02637\n",
      "Epoch: 0023 train_loss= 49.79035 train_acc= 0.96667 val_loss= 248.60875 val_acc= 0.48000 time= 0.02496\n",
      "Epoch: 0024 train_loss= 49.30558 train_acc= 0.95833 val_loss= 248.83067 val_acc= 0.47400 time= 0.02962\n",
      "Epoch: 0025 train_loss= 48.51762 train_acc= 0.98333 val_loss= 249.04913 val_acc= 0.47200 time= 0.02816\n",
      "Epoch: 0026 train_loss= 48.48784 train_acc= 0.97500 val_loss= 249.28865 val_acc= 0.47200 time= 0.02649\n",
      "Epoch: 0027 train_loss= 47.94374 train_acc= 0.96667 val_loss= 249.55049 val_acc= 0.46600 time= 0.02684\n",
      "Epoch: 0028 train_loss= 48.05190 train_acc= 0.95000 val_loss= 249.82002 val_acc= 0.47000 time= 0.02972\n",
      "Epoch: 0029 train_loss= 47.26234 train_acc= 0.95833 val_loss= 250.09509 val_acc= 0.46200 time= 0.04281\n",
      "Epoch: 0030 train_loss= 47.75624 train_acc= 0.96667 val_loss= 250.39604 val_acc= 0.44800 time= 0.03117\n",
      "Epoch: 0031 train_loss= 47.65497 train_acc= 0.95833 val_loss= 250.70490 val_acc= 0.42200 time= 0.02935\n",
      "Epoch: 0032 train_loss= 47.13194 train_acc= 0.96667 val_loss= 251.00990 val_acc= 0.40400 time= 0.02962\n",
      "Epoch: 0033 train_loss= 46.48621 train_acc= 0.96667 val_loss= 251.28087 val_acc= 0.38800 time= 0.03092\n",
      "Epoch: 0034 train_loss= 46.31586 train_acc= 0.96667 val_loss= 251.52211 val_acc= 0.38200 time= 0.02898\n",
      "Epoch: 0035 train_loss= 46.18010 train_acc= 0.95833 val_loss= 251.75668 val_acc= 0.38200 time= 0.02729\n",
      "Epoch: 0036 train_loss= 46.22196 train_acc= 0.96667 val_loss= 251.95967 val_acc= 0.38000 time= 0.02827\n",
      "Epoch: 0037 train_loss= 46.43718 train_acc= 0.94167 val_loss= 252.16376 val_acc= 0.37000 time= 0.02949\n",
      "Epoch: 0038 train_loss= 45.64278 train_acc= 0.96667 val_loss= 252.34064 val_acc= 0.35600 time= 0.03363\n",
      "Epoch: 0039 train_loss= 45.40736 train_acc= 0.96667 val_loss= 252.51494 val_acc= 0.34600 time= 0.03588\n",
      "Epoch: 0040 train_loss= 45.31284 train_acc= 0.99167 val_loss= 252.70706 val_acc= 0.34000 time= 0.02774\n",
      "Epoch: 0041 train_loss= 44.51756 train_acc= 0.95833 val_loss= 252.89246 val_acc= 0.33800 time= 0.02676\n",
      "Epoch: 0042 train_loss= 44.43282 train_acc= 0.98333 val_loss= 253.04561 val_acc= 0.32600 time= 0.02707\n",
      "Epoch: 0043 train_loss= 44.75128 train_acc= 0.97500 val_loss= 253.19846 val_acc= 0.32200 time= 0.02613\n",
      "Epoch: 0044 train_loss= 44.45513 train_acc= 0.98333 val_loss= 253.34180 val_acc= 0.31800 time= 0.02494\n",
      "Epoch: 0045 train_loss= 44.96524 train_acc= 0.95000 val_loss= 253.49577 val_acc= 0.32000 time= 0.02514\n",
      "Epoch: 0046 train_loss= 44.48146 train_acc= 0.95833 val_loss= 253.65039 val_acc= 0.32200 time= 0.02781\n",
      "Epoch: 0047 train_loss= 44.08940 train_acc= 0.98333 val_loss= 253.83078 val_acc= 0.32600 time= 0.02740\n",
      "Epoch: 0048 train_loss= 44.15218 train_acc= 0.96667 val_loss= 253.97881 val_acc= 0.32800 time= 0.02578\n",
      "Epoch: 0049 train_loss= 44.28667 train_acc= 0.95833 val_loss= 254.13072 val_acc= 0.34200 time= 0.02579\n",
      "Epoch: 0050 train_loss= 43.63137 train_acc= 0.98333 val_loss= 254.25414 val_acc= 0.34000 time= 0.02612\n",
      "Epoch: 0051 train_loss= 43.66515 train_acc= 0.99167 val_loss= 254.35028 val_acc= 0.33600 time= 0.02650\n",
      "Epoch: 0052 train_loss= 43.30203 train_acc= 0.96667 val_loss= 254.44226 val_acc= 0.34000 time= 0.02595\n",
      "Epoch: 0053 train_loss= 43.15819 train_acc= 0.98333 val_loss= 254.51926 val_acc= 0.34000 time= 0.02492\n",
      "Epoch: 0054 train_loss= 44.62138 train_acc= 0.96667 val_loss= 254.57066 val_acc= 0.34200 time= 0.02610\n",
      "Epoch: 0055 train_loss= 42.89776 train_acc= 0.96667 val_loss= 254.59779 val_acc= 0.34000 time= 0.02610\n",
      "Epoch: 0056 train_loss= 43.53904 train_acc= 0.99167 val_loss= 254.63818 val_acc= 0.33000 time= 0.02541\n",
      "Epoch: 0057 train_loss= 43.80014 train_acc= 0.95000 val_loss= 254.67938 val_acc= 0.32000 time= 0.02671\n",
      "Epoch: 0058 train_loss= 43.00464 train_acc= 0.95000 val_loss= 254.69392 val_acc= 0.31200 time= 0.02541\n",
      "Epoch: 0059 train_loss= 43.08628 train_acc= 0.96667 val_loss= 254.71744 val_acc= 0.30600 time= 0.02582\n",
      "Epoch: 0060 train_loss= 42.99224 train_acc= 0.97500 val_loss= 254.74857 val_acc= 0.30200 time= 0.02461\n",
      "Epoch: 0061 train_loss= 42.77277 train_acc= 0.97500 val_loss= 254.80122 val_acc= 0.29400 time= 0.02684\n",
      "Epoch: 0062 train_loss= 42.61523 train_acc= 0.97500 val_loss= 254.86253 val_acc= 0.29000 time= 0.02629\n",
      "Epoch: 0063 train_loss= 43.23264 train_acc= 0.98333 val_loss= 254.90031 val_acc= 0.28600 time= 0.02596\n",
      "Epoch: 0064 train_loss= 42.51894 train_acc= 0.95833 val_loss= 254.99139 val_acc= 0.28400 time= 0.02613\n",
      "Epoch: 0065 train_loss= 41.94604 train_acc= 0.98333 val_loss= 255.10764 val_acc= 0.28400 time= 0.02580\n",
      "Epoch: 0066 train_loss= 43.03791 train_acc= 0.96667 val_loss= 255.19225 val_acc= 0.28200 time= 0.02580\n",
      "Epoch: 0067 train_loss= 41.64474 train_acc= 0.99167 val_loss= 255.29308 val_acc= 0.28200 time= 0.02547\n",
      "Epoch: 0068 train_loss= 42.54066 train_acc= 0.98333 val_loss= 255.37679 val_acc= 0.28000 time= 0.02531\n",
      "Epoch: 0069 train_loss= 42.25238 train_acc= 0.98333 val_loss= 255.48981 val_acc= 0.28400 time= 0.02546\n",
      "Epoch: 0070 train_loss= 42.74714 train_acc= 0.95833 val_loss= 255.58659 val_acc= 0.28200 time= 0.02640\n",
      "Epoch: 0071 train_loss= 41.81598 train_acc= 0.98333 val_loss= 255.63551 val_acc= 0.28200 time= 0.02618\n",
      "Epoch: 0072 train_loss= 43.05436 train_acc= 0.97500 val_loss= 255.65292 val_acc= 0.28200 time= 0.02602\n",
      "Epoch: 0073 train_loss= 42.67590 train_acc= 0.96667 val_loss= 255.62617 val_acc= 0.28000 time= 0.02618\n",
      "Epoch: 0074 train_loss= 41.84826 train_acc= 0.97500 val_loss= 255.60838 val_acc= 0.27000 time= 0.02540\n",
      "Epoch: 0075 train_loss= 41.41366 train_acc= 0.96667 val_loss= 255.58250 val_acc= 0.26800 time= 0.02645\n",
      "Epoch: 0076 train_loss= 41.43992 train_acc= 0.97500 val_loss= 255.57278 val_acc= 0.26800 time= 0.02546\n",
      "Epoch: 0077 train_loss= 41.41600 train_acc= 0.99167 val_loss= 255.60971 val_acc= 0.27400 time= 0.02655\n",
      "Epoch: 0078 train_loss= 41.55595 train_acc= 0.99167 val_loss= 255.66475 val_acc= 0.27400 time= 0.02567\n",
      "Epoch: 0079 train_loss= 41.45126 train_acc= 0.96667 val_loss= 255.69521 val_acc= 0.27200 time= 0.02471\n",
      "Epoch: 0080 train_loss= 40.89023 train_acc= 0.95000 val_loss= 255.71288 val_acc= 0.27200 time= 0.02491\n",
      "Epoch: 0081 train_loss= 41.90391 train_acc= 0.97500 val_loss= 255.76114 val_acc= 0.27000 time= 0.02569\n",
      "Epoch: 0082 train_loss= 41.55239 train_acc= 0.96667 val_loss= 255.80548 val_acc= 0.26400 time= 0.02595\n",
      "Epoch: 0083 train_loss= 41.10740 train_acc= 0.99167 val_loss= 255.88594 val_acc= 0.26400 time= 0.03398\n",
      "Epoch: 0084 train_loss= 41.56655 train_acc= 1.00000 val_loss= 255.96434 val_acc= 0.25800 time= 0.02709\n",
      "Epoch: 0085 train_loss= 41.76411 train_acc= 0.96667 val_loss= 256.09781 val_acc= 0.25600 time= 0.02623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0086 train_loss= 41.16063 train_acc= 0.97500 val_loss= 256.22589 val_acc= 0.25600 time= 0.02574\n",
      "Epoch: 0087 train_loss= 40.18763 train_acc= 0.97500 val_loss= 256.33493 val_acc= 0.25800 time= 0.02605\n",
      "Epoch: 0088 train_loss= 40.97846 train_acc= 0.96667 val_loss= 256.49341 val_acc= 0.25800 time= 0.02682\n",
      "Epoch: 0089 train_loss= 41.22199 train_acc= 0.97500 val_loss= 256.63733 val_acc= 0.26000 time= 0.02596\n",
      "Epoch: 0090 train_loss= 40.52702 train_acc= 0.98333 val_loss= 256.78549 val_acc= 0.25600 time= 0.02591\n",
      "Epoch: 0091 train_loss= 40.36060 train_acc= 0.97500 val_loss= 256.87115 val_acc= 0.25600 time= 0.02585\n",
      "Epoch: 0092 train_loss= 41.18401 train_acc= 0.95000 val_loss= 256.87802 val_acc= 0.25400 time= 0.02628\n",
      "Epoch: 0093 train_loss= 41.08439 train_acc= 0.97500 val_loss= 256.87320 val_acc= 0.25400 time= 0.02564\n",
      "Epoch: 0094 train_loss= 40.76528 train_acc= 0.99167 val_loss= 256.88217 val_acc= 0.25200 time= 0.02546\n",
      "Epoch: 0095 train_loss= 41.12056 train_acc= 0.99167 val_loss= 256.85782 val_acc= 0.25200 time= 0.02629\n",
      "Epoch: 0096 train_loss= 40.64199 train_acc= 0.96667 val_loss= 256.84079 val_acc= 0.25200 time= 0.02519\n",
      "Epoch: 0097 train_loss= 41.09359 train_acc= 0.96667 val_loss= 256.80115 val_acc= 0.25400 time= 0.02560\n",
      "Epoch: 0098 train_loss= 40.80972 train_acc= 0.96667 val_loss= 256.76645 val_acc= 0.25200 time= 0.02498\n",
      "Epoch: 0099 train_loss= 39.97892 train_acc= 0.98333 val_loss= 256.75082 val_acc= 0.25200 time= 0.02609\n",
      "Epoch: 0100 train_loss= 41.62796 train_acc= 0.95833 val_loss= 256.83881 val_acc= 0.25400 time= 0.02597\n",
      "Epoch: 0101 train_loss= 41.07771 train_acc= 0.96667 val_loss= 256.92624 val_acc= 0.25400 time= 0.02542\n",
      "Epoch: 0102 train_loss= 40.80237 train_acc= 0.98333 val_loss= 257.02249 val_acc= 0.25400 time= 0.02626\n",
      "Early stopping...\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Initialize weights\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "train_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "\n",
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "    \n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, y_val, val_mask, placeholders)\n",
    "    validation_loss.append(cost)\n",
    "    validation_accuracy.append(acc)\n",
    "    train_loss.append(outs[1])\n",
    "    train_accuracy.append(outs[2])\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and validation_loss[-1] > np.mean(validation_loss[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ac3f2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(train_accuracy,label = 'train_accuracy')\n",
    "plt.plot(train_loss,label = 'train_loss')\n",
    "plt.plot(validation_accuracy, label='validation_accuracy')\n",
    "plt.plot(validation_loss,label='validaton_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
